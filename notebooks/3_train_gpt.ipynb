{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.0 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.0/61.0 kB 819.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.5.15-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.3-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "Using cached huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB 8.9 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.8/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.5/15.8 MB 11.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.9/15.8 MB 10.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.4/15.8 MB 11.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.7/15.8 MB 10.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.3/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.8/15.8 MB 10.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.8/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.3/15.8 MB 10.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.9/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 7.1/15.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.7/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.2/15.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 11.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.4/15.8 MB 11.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.0/15.8 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.6/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.6/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 11.3 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Using cached regex-2024.5.15-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Using cached safetensors-0.4.3-cp311-none-win_amd64.whl (287 kB)\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.1 kB ? eta -:--:--\n",
      "   -------------------------------------- - 307.2/316.1 kB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 316.1/316.1 kB 9.6 MB/s eta 0:00:00\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.1 idna-3.7 numpy-1.26.4 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.2 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.1 urllib3-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (0.23.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "Using cached pyarrow-16.1.0-cp311-cp311-win_amd64.whl (25.9 MB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.5.0\n",
      "    Uninstalling fsspec-2024.5.0:\n",
      "      Successfully uninstalled fsspec-2024.5.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 datasets-2.19.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.3.1 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.1.0 pyarrow-hotfix-0.6 pytz-2024.1 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.3.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.18.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.3.0-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch) (4.12.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached torchvision-0.18.0-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "Using cached torchaudio-2.3.0-cp311-cp311-win_amd64.whl (2.4 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/2.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 0.5/2.5 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.9/2.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.4/2.5 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.0/2.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.3/133.3 kB 8.2 MB/s eta 0:00:00\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, pillow, networkx, mkl, MarkupSafe, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 pillow-10.3.0 sympy-1.12 tbb-2021.12.0 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.3.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: c:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, mkl, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, torchaudio, torchvision\n"
     ]
    }
   ],
   "source": [
    "!pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (0.30.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.12.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kevin\\mads-capstone-project\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1352/1352 [00:00<00:00, 1917.65 examples/s]\n",
      "c:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 44\u001b[0m\n\u001b[0;32m     26\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     27\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# No save is done during training.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     38\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     preprocess_logits_for_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     42\u001b[0m )\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\\transformers\\trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\\transformers\\trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2222\u001b[0m ):\n\u001b[0;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\mads-capstone-project\\.venv\\Lib\\site-packages\\transformers\\trainer.py:3282\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 3282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3284\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3285\u001b[0m         )\n\u001b[0;32m   3286\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   3287\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "processed_output_file = \"../data/processed/processed_personas_text.txt\"\n",
    "\n",
    "with open(processed_output_file, 'r', encoding='utf-8') as f:\n",
    "    processed_text = f.read()\n",
    "\n",
    "max_length = 512\n",
    "text_chunks = [processed_text[i:i+max_length] for i in range(0, len(processed_text), max_length)]\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": text_chunks})\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the pad_token to eos_token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    encoding = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    encoding[\"labels\"] = encoding[\"input_ids\"].copy()\n",
    "    return encoding\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../models/fine-tuned-gpt2\")\n",
    "tokenizer.save_pretrained(\"../models/fine-tuned-gpt2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
